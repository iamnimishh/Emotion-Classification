{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oP-fgSp97oFv"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sanidhyak/human-face-emotions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNBzQgvu76qn",
        "outputId": "1a52bc07-0ae4-4240-d510-677907b86239"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "human-face-emotions.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref=zipfile.ZipFile('/content/human-face-emotions.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "FODibuAM76yO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "# Set the path to your dataset folders\n",
        "happy_path = '/content/data/Happy'\n",
        "sad_path = '/content/data/Sad'\n",
        "angry_path = '/content/data/Angry'\n",
        "\n"
      ],
      "metadata": {
        "id": "S8H8R4hv761H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images\n",
        "def load_images(folder_path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = Image.open(img_path)\n",
        "        img_resized = resize(np.array(img), (64, 64, 3))  # Resize images to a consistent size\n",
        "        images.append(img_resized)\n",
        "        labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Load and preprocess images from each emotion folder\n",
        "happy_images, happy_labels = load_images(happy_path, 0)\n",
        "sad_images, sad_labels = load_images(sad_path, 1)\n",
        "angry_images, angry_labels = load_images(angry_path, 2)\n",
        "\n",
        "# Combine the images and labels from all emotion categories\n",
        "images = np.concatenate([happy_images, sad_images, angry_images])\n",
        "labels = np.concatenate([happy_labels, sad_labels, angry_labels])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to categorical format\n",
        "num_classes = 3  # Happy, Sad, Angry\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "v1uIiFeAe6e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "learning_rate = 0.0001\n",
        "batch_size = 4\n",
        "epochs = 20\n",
        "\n",
        "# Initialize variables to track best epoch and its accuracy\n",
        "best_epoch = 0\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Train the model for different numbers of epochs and track validation accuracy\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # Define the CNN model architecture\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model with specified learning rate\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model with specified batch size and current number of epochs\n",
        "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epoch, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Print the validation accuracy for the current epoch\n",
        "    print(f\"Epoch {epoch}/{epochs} - Validation Accuracy: {accuracy}\")\n",
        "\n",
        "    # Check if the current accuracy is better than the previous best accuracy\n",
        "    if accuracy > best_accuracy:\n",
        "        best_epoch = epoch\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "# Print the best epoch and its accuracy\n",
        "print(f\"\\nBest Epoch: {best_epoch}\")\n",
        "print(f\"Best Accuracy: {best_accuracy}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM7j3E11gQo6",
        "outputId": "81b85d37-031d-4059-e430-245e3c23325f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 2/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 3/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 4/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 5/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 6/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 7/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 8/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 9/20 - Validation Accuracy: 0.2641509473323822\n",
            "Epoch 10/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 11/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 12/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 13/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 14/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 15/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 16/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 17/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 18/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 19/20 - Validation Accuracy: 0.43396225571632385\n",
            "Epoch 20/20 - Validation Accuracy: 0.43396225571632385\n",
            "\n",
            "Best Epoch: 1\n",
            "Best Accuracy: 0.43396225571632385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with the best number of epochs\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=best_epoch, validation_data=(X_test, y_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "-M3TtbaGgQzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new images (replace 'path/to/new/image.jpg' with the path to your image)\n",
        "new_image = Image.open('/content/data/Angry/32209658.jpg')\n",
        "new_image_resized = resize(np.array(new_image), (64, 64, 3))\n",
        "new_image_rescaled = new_image_resized.astype('float32') / 255.0\n",
        "new_image_reshaped = np.expand_dims(new_image_rescaled, axis=0)\n",
        "prediction = model.predict(new_image_reshaped)\n",
        "emotion_label = np.argmax(prediction)\n",
        "\n",
        "# Mapping the predicted label to the corresponding emotion category\n",
        "emotion_categories = ['Happy', 'Sad', 'Angry']\n",
        "predicted_emotion = emotion_categories[emotion_label]\n",
        "print('Predicted emotion:', predicted_emotion)"
      ],
      "metadata": {
        "id": "3FOYmrS3g1y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new images (replace 'path/to/new/image.jpg' with the path to your image)\n",
        "new_image = Image.open('/content/data/Happy/35438_hd.jpg')\n",
        "new_image_resized = resize(np.array(new_image), (64, 64, 3))\n",
        "new_image_rescaled = new_image_resized.astype('float32') / 255.0\n",
        "new_image_reshaped = np.expand_dims(new_image_rescaled, axis=0)\n",
        "prediction = model.predict(new_image_reshaped)\n",
        "emotion_label = np.argmax(prediction)\n",
        "\n",
        "# Mapping the predicted label to the corresponding emotion category\n",
        "emotion_categories = ['Happy', 'Sad', 'Angry']\n",
        "predicted_emotion = emotion_categories[emotion_label]\n",
        "print('Predicted emotion:', predicted_emotion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-sG3TVHAL6H",
        "outputId": "ceea6cea-4792-4b72-bca9-940db5d465a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted emotion: Angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Transfer learning is a powerful technique that allows us to leverage pre-trained models and their learned features to enhance the performance of our own models with limited training data.\n",
        "### 2. By using the VGG16 pre-trained model, we can benefit from the extensive knowledge it gained from the ImageNet dataset, which can be particularly useful in tasks like emotion classification.\n",
        "### 3. The best epoch, identified as epoch 47, achieved an accuracy of 0.5660, demonstrating the effectiveness of transfer learning and the potential improvement it can bring to emotion classification tasks.\n",
        "### 4. The code provided showcases the complete process, from loading and preprocessing the dataset to training the model, evaluating its performance, and making predictions on new images.\n",
        "### 5. The ability to accurately predict emotions from images has important applications in various fields, including psychology, marketing, and human-computer interaction, and this transfer learning approach contributes to enhancing the accuracy and reliability of such predictions."
      ],
      "metadata": {
        "id": "jG8OrB9NbCvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that there is no significant improvement in the validation accuracy across different epochs. This could indicate that the model may have reached its limit in learning from the available data or that the dataset itself may not have enough information to accurately classify the emotions.\n",
        "\n",
        "In such cases, it is worth considering other approaches to improve the model's performance:\n",
        "\n",
        "1. **Collect more data**: Increasing the dataset size with more diverse and representative images can provide the model with more information to learn from and potentially improve its performance.\n",
        "\n",
        "2. **Data augmentation**: Apply various transformations (rotation, scaling, flipping, etc.) to the existing images to create additional training samples. This technique can help the model generalize better and reduce overfitting.\n",
        "\n",
        "3. **Transfer learning**: Utilize pre-trained models, such as those from the ImageNet dataset, and adapt them for emotion classification. Transfer learning allows leveraging the knowledge learned from a large dataset to improve performance, especially when you have limited training data.\n",
        "\n",
        "4. **Experiment with different architectures**: Try different CNN architectures, layer configurations, and hyperparameters. Consider increasing the depth or width of the network, adding more convolutional or dense layers, or adjusting the dropout rate to regularize the model.\n",
        "\n",
        "5. **Hyperparameter tuning**: Explore different learning rates, batch sizes, optimizers, and regularization techniques. You can use techniques like learning rate schedules or early stopping to optimize the training process.\n",
        "\n",
        "6. **Address class imbalance**: If the dataset has imbalanced class distributions, apply techniques like oversampling, undersampling, or class weights to balance the classes during training.\n",
        "\n",
        "7. **Ensemble models**: Train multiple models with different architectures or hyperparameters and combine their predictions using voting or averaging to improve the overall performance.\n"
      ],
      "metadata": {
        "id": "hqEtloLSbWvs"
      }
    }
  ]
}